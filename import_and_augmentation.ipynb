{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mitosplit_net import preprocessing, augmentation, evaluation, training, plotting, util\n",
    "from albumentations import Compose, Rotate, RandomRotate90, HorizontalFlip, Flip, ElasticTransform, GaussNoise, RandomCrop, Resize\n",
    "from tqdm import tqdm\n",
    "import os, sys\n",
    "from os import path\n",
    "import random as r\n",
    "from import_augmentation_function import import_fun, aug_fun, import_aug_fun, normalization_fun\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choice of folder and number of augmentations ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "files_dir = r'C:\\Users\\roumba\\Documents\\Software\\deep-events\\training_data'\n",
    "images_dir = '220915_mtstaygold_cos7_ZEISS_fl_pos'\n",
    "date, dye, cell_type, microscope, bf_fl, pos_neg = images_dir.split('_')\n",
    "joined_path = os.path.join(files_dir, images_dir)\n",
    "img_size = 256\n",
    "data_ratio=0.1\n",
    "data_split_state = None \n",
    "number_of_augmentations = 5 \n",
    "\n",
    "#for some reason, even though it should have been deleted, the first two arrays of axis0 are zeros?# \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Split ##\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 166/166 [00:00<00:00, 1597.08it/s]\n",
      "100%|██████████| 166/166 [00:00<00:00, 1825.13it/s]\n",
      "100%|██████████| 166/166 [00:00<00:00, 1694.82it/s]\n",
      "100%|██████████| 166/166 [00:00<00:00, 1766.96it/s]\n",
      "100%|██████████| 166/166 [00:00<00:00, 1909.12it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_image_array, all_image_array_gauss = import_fun(joined_path, files_dir, images_dir)\n",
    "augmentation_data, data_val, augmentation_data_gauss, data_gauss_val =  train_test_split(all_image_array, all_image_array_gauss, \n",
    "                                                                                                       test_size=data_ratio, random_state=data_split_state)\n",
    "data_aug = augmentation_data\n",
    "data_gauss_aug = augmentation_data_gauss\n",
    "for j in range(number_of_augmentations):\n",
    "    augment_data, augment_data_gauss = aug_fun(augmentation_data, augmentation_data_gauss)\n",
    "    data_aug = np.concatenate((data_aug, augment_data))\n",
    "    data_gauss_aug = np.concatenate((data_gauss_aug,augment_data_gauss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization and Shuffle ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val_norm, data_aug_norm, data_gauss_val_norm, data_gauss_aug_norm = normalization_fun(data_val, data_aug, data_gauss_val, data_gauss_aug)\n",
    "\n",
    "r.shuffle(data_val_norm)\n",
    "r.shuffle(data_gauss_val_norm)\n",
    "r.shuffle(data_aug_norm)\n",
    "r.shuffle(data_gauss_aug_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define GPU device ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "gpu = tf.config.list_physical_devices('GPU')[0]\n",
    "print(gpu)\n",
    "tf.config.experimental.set_memory_growth(gpu, True)\n",
    "gpu = tf.device('GPU:0/') \n",
    "\n",
    "base_dir = r'C:\\Users\\roumba\\Documents\\Software\\deep-events'\n",
    "data_path = base_dir+ r'\\Norm_data'\n",
    "model_path = base_dir+ '\\Models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: ref_f8_c9_b16\n",
      "* Start Encoder Section *\n",
      "* Start Center Section *\n",
      "* Start Decoder Section *\n",
      "Epoch 1/20\n",
      "56/56 - 21s - loss: 0.9313 - binary_accuracy: 0.2192 - val_loss: 0.6911 - val_binary_accuracy: 0.6423 - 21s/epoch - 373ms/step\n",
      "Epoch 2/20\n",
      "56/56 - 15s - loss: 0.6382 - binary_accuracy: 0.8052 - val_loss: 0.6186 - val_binary_accuracy: 0.9732 - 15s/epoch - 269ms/step\n",
      "Epoch 3/20\n",
      "56/56 - 15s - loss: 0.5604 - binary_accuracy: 0.9885 - val_loss: 0.5454 - val_binary_accuracy: 0.9962 - 15s/epoch - 269ms/step\n",
      "Epoch 4/20\n",
      "56/56 - 15s - loss: 0.5214 - binary_accuracy: 0.9928 - val_loss: 0.4963 - val_binary_accuracy: 0.9962 - 15s/epoch - 269ms/step\n",
      "Epoch 5/20\n",
      "56/56 - 15s - loss: 0.4892 - binary_accuracy: 0.9926 - val_loss: 0.4540 - val_binary_accuracy: 0.9945 - 15s/epoch - 268ms/step\n",
      "Epoch 6/20\n",
      "56/56 - 15s - loss: 0.4566 - binary_accuracy: 0.9935 - val_loss: 0.4200 - val_binary_accuracy: 0.9952 - 15s/epoch - 269ms/step\n",
      "Epoch 7/20\n",
      "56/56 - 15s - loss: 0.4298 - binary_accuracy: 0.9921 - val_loss: 0.4502 - val_binary_accuracy: 0.9960 - 15s/epoch - 269ms/step\n",
      "Epoch 8/20\n",
      "56/56 - 15s - loss: 0.3956 - binary_accuracy: 0.9940 - val_loss: 0.4070 - val_binary_accuracy: 0.9962 - 15s/epoch - 269ms/step\n",
      "Epoch 9/20\n",
      "56/56 - 15s - loss: 0.3660 - binary_accuracy: 0.9945 - val_loss: 0.3819 - val_binary_accuracy: 0.9956 - 15s/epoch - 269ms/step\n",
      "Epoch 10/20\n",
      "56/56 - 15s - loss: 0.3387 - binary_accuracy: 0.9947 - val_loss: 0.3518 - val_binary_accuracy: 0.9959 - 15s/epoch - 268ms/step\n",
      "Epoch 11/20\n",
      "56/56 - 15s - loss: 0.3121 - binary_accuracy: 0.9950 - val_loss: 0.3223 - val_binary_accuracy: 0.9958 - 15s/epoch - 268ms/step\n",
      "Epoch 12/20\n",
      "56/56 - 15s - loss: 0.2877 - binary_accuracy: 0.9952 - val_loss: 0.2953 - val_binary_accuracy: 0.9958 - 15s/epoch - 268ms/step\n",
      "Epoch 13/20\n",
      "56/56 - 15s - loss: 0.2647 - binary_accuracy: 0.9954 - val_loss: 0.2694 - val_binary_accuracy: 0.9957 - 15s/epoch - 269ms/step\n",
      "Epoch 14/20\n",
      "56/56 - 15s - loss: 0.2436 - binary_accuracy: 0.9955 - val_loss: 0.2467 - val_binary_accuracy: 0.9957 - 15s/epoch - 269ms/step\n",
      "Epoch 15/20\n",
      "56/56 - 15s - loss: 0.2239 - binary_accuracy: 0.9956 - val_loss: 0.2198 - val_binary_accuracy: 0.9962 - 15s/epoch - 269ms/step\n",
      "Epoch 16/20\n",
      "56/56 - 15s - loss: 0.2059 - binary_accuracy: 0.9957 - val_loss: 0.1993 - val_binary_accuracy: 0.9962 - 15s/epoch - 268ms/step\n",
      "Epoch 17/20\n",
      "56/56 - 15s - loss: 0.1898 - binary_accuracy: 0.9957 - val_loss: 0.1825 - val_binary_accuracy: 0.9962 - 15s/epoch - 269ms/step\n",
      "Epoch 18/20\n",
      "56/56 - 15s - loss: 0.1743 - binary_accuracy: 0.9957 - val_loss: 0.1662 - val_binary_accuracy: 0.9953 - 15s/epoch - 268ms/step\n",
      "Epoch 19/20\n",
      "56/56 - 15s - loss: 0.1604 - binary_accuracy: 0.9957 - val_loss: 0.1515 - val_binary_accuracy: 0.9962 - 15s/epoch - 269ms/step\n",
      "Epoch 20/20\n",
      "56/56 - 15s - loss: 0.1471 - binary_accuracy: 0.9958 - val_loss: 0.1378 - val_binary_accuracy: 0.9962 - 15s/epoch - 269ms/step\n"
     ]
    }
   ],
   "source": [
    "with gpu:\n",
    "  nb_filters = 8\n",
    "  firstConvSize = 9\n",
    "  batch_size = [8, 16, 32, 256]\n",
    "  model, history= {}, {}\n",
    "  \n",
    "  b=batch_size[1]\n",
    "  model_name = 'ref_f%i_c%i_b%i'%(nb_filters, firstConvSize, b)\n",
    "  print('Model:', model_name)\n",
    "  model[model_name] = training.create_model(nb_filters, firstConvSize)\n",
    "  history[model_name] = training.train_model(model[model_name], data_aug_norm, data_gauss_aug_norm, b, data_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving of Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving C:\\Users\\roumba\\Documents\\Software\\deep-events\\Norm_data\\cos7_ZEISS_fl_data_val_.h5\n",
      "Done.\n",
      "\n",
      "Saving C:\\Users\\roumba\\Documents\\Software\\deep-events\\Norm_data\\cos7_ZEISS_fl_data_gauss_val.h5\n",
      "Done.\n",
      "\n",
      "Saving C:\\Users\\roumba\\Documents\\Software\\deep-events\\Norm_data\\cos7_ZEISS_fl_data_aug.h5\n",
      "Done.\n",
      "\n",
      "Saving C:\\Users\\roumba\\Documents\\Software\\deep-events\\Norm_data\\cos7_ZEISS_fl_data_gauss_aug.h5\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "folder_name = list(model.keys())\n",
    "name1=f'\\{cell_type}_{microscope}_{bf_fl}_data_val'\n",
    "name2=f'\\{cell_type}_{microscope}_{bf_fl}_data_gauss_val'\n",
    "name3=f'\\{cell_type}_{microscope}_{bf_fl}_data_aug'\n",
    "name4=f'\\{cell_type}_{microscope}_{bf_fl}_data_gauss_aug'\n",
    "\n",
    "util.save_h5(data_val_norm, data_path, name1)\n",
    "util.save_h5(data_gauss_val_norm, data_path, name2)\n",
    "util.save_h5(data_aug_norm, data_path, name3)\n",
    "util.save_h5(data_gauss_aug_norm, data_path, name4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'napari'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnapari\u001b[39;00m\n\u001b[0;32m      2\u001b[0m viewer \u001b[39m=\u001b[39m napari\u001b[39m.\u001b[39mViewer()\n\u001b[0;32m      3\u001b[0m viewer\u001b[39m.\u001b[39madd_image(data_val_norm)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'napari'"
     ]
    }
   ],
   "source": [
    "import napari\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(data_val_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving C:\\Users\\roumba\\Documents\\Software\\deep-events\\Modelsref_f8_c9_b16/model.h5\n",
      "Done.\n",
      "\n",
      "Saving C:\\Users\\roumba\\Documents\\Software\\deep-events\\Modelsref_f8_c9_b16/history\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "util.save_model(model, model_path, [f'model']*len(model), folder_name)\n",
    "util.save_pkl(history, model_path, [f'history']*len(model), folder_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1eaf8819518d82bc7e7f729f546a337f692f85bf6d00cdfaf0712e2fc6595813"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
