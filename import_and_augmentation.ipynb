{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from os import path\n",
    "import random \n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow\n",
    "import imageio\n",
    "from scipy import signal\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTS ALL IMAGES WITHIN THE FOLDER \"imager_dir\" INTO TWO ARRAYS, ONE FOR GAUSS POINTS AND ONE FOR IMAGE CROPS ##\n",
    "all_image_array=np.zeros((256,256))[None, :, :]\n",
    "all_image_array_gauss=np.zeros((256,256))[None, :, :]\n",
    "\n",
    "files_dir = r'C:\\Users\\roumba\\Documents\\Software\\deep-events\\training_data'\n",
    "images_dir = '220915_mtstaygold_cos7_ZEISS_bf_pos'\n",
    "joined_path = os.path.join(files_dir, images_dir)\n",
    "\n",
    "for image_file in os.listdir(joined_path):\n",
    "    image, date, cell_type, bf_fl, index, number_gauss  = image_file.split('_')\n",
    "    joined_image_path = os.path.join(files_dir, images_dir, image_file)\n",
    "\n",
    "    if 'gauss' in number_gauss:\n",
    "        img_gauss = Image.open(joined_image_path)\n",
    "        image_array_gauss = np.zeros((img_gauss.n_frames,256,256))\n",
    "        for i in range(img_gauss.n_frames-1):\n",
    "            img_gauss.seek(i)\n",
    "            image_array_gauss[i,:,:] = np.array(img_gauss)\n",
    "        all_image_array_gauss = np.concatenate([all_image_array_gauss, image_array_gauss])\n",
    "    else:\n",
    "        img = Image.open(joined_image_path)\n",
    "        image_array = np.zeros((img.n_frames,256,256))\n",
    "        for i in range(img.n_frames-1):\n",
    "            img.seek(i)\n",
    "            image_array[i,:,:] = np.array(img)\n",
    "        all_image_array = np.concatenate([all_image_array, image_array])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DATA SPLIT INTO VALIDATION AND AUGMENTATION ##\n",
    "\n",
    "data_set_test_trainvalid_ratio = 0.1\n",
    "data_split_state = None   # Random split on each call\n",
    "augmentation_data, validation_data, augmentation_data_gauss, validation_data_gauss =  train_test_split(all_image_array, all_image_array_gauss, \n",
    "                                                                                                       test_size=data_set_test_trainvalid_ratio, random_state=data_split_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ANYTHING BELOW THIS POINT IS EDITS ON MITOSPLITNET CODE ##\n",
    "from mitosplit_net import preprocessing, augmentation, evaluation, training, plotting, util\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import label2rgb\n",
    "from skimage import segmentation\n",
    "from albumentations import Compose, Rotate, RandomRotate90, HorizontalFlip, Flip, ElasticTransform, GaussNoise, RandomCrop, Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AUGMENTATION OF DATA (I need to go through this again) ##\n",
    "\n",
    "def augImg(input_img, output_img, transform, **kwargs):\n",
    "    input_mask = (input_img>0).astype(np.uint8)\n",
    "    transformed = transform(image=input_img, image0=output_img)\n",
    "    \n",
    "    aug_input_img, aug_output_img= transformed['image'], transformed['image0']\n",
    "    \n",
    "    # aug_fission_coords = preprocessing.fissionCoords(aug_labels, aug_output_img)\n",
    "    # aug_output_img, aug_fission_props = preprocessing.prepareProc(aug_output_img, coords=aug_fission_coords, **kwargs)\n",
    "    return aug_input_img.astype(np.uint8), aug_output_img\n",
    "    \n",
    "\n",
    "def augStack(input_data, output_data, transform, **kwargs):\n",
    "    aug_input_data = np.zeros(input_data.shape, dtype=np.uint8)\n",
    "    aug_output_data = np.zeros(output_data.shape, dtype=np.float32)\n",
    "    \n",
    "    for i in tqdm(range(input_data.shape[0]), total=input_data.shape[0]):\n",
    "        aug_input_data[i], aug_output_data[i]= augImg(input_data[i], output_data[i], transform, **kwargs)\n",
    "    return aug_input_data, aug_output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 520/520 [00:00<00:00, 1472.88it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(520, 256, 256)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_size = 256\n",
    "transform = Compose([RandomRotate90(p=0.5), HorizontalFlip(p=0.5), Flip(p=0.5)])\n",
    "\n",
    "aug_data, aug_data_gauss= augStack(augmentation_data, augmentation_data_gauss,transform, sigma=8)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1eaf8819518d82bc7e7f729f546a337f692f85bf6d00cdfaf0712e2fc6595813"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
