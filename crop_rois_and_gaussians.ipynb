{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os import path\n",
    "import xmltodict\n",
    "from myfunctions import event_separation , image_crop, image_crop_negative, poi, \n",
    "from myfunctions import delete_old_extracted_events\n",
    "from database.extract_yaml import get_dict\n",
    "import tifffile\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = r'//lebnas1.epfl.ch/microsc125/deep_events'\n",
    "SAVING_SCHEME = \"ws_0.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data from a folder ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_dir = os.path.join(BASE_DIR, 'original_data')\n",
    "images_dir = '221123_mtStayGold_U2OS_ZEISS_fl'\n",
    "joined_path = os.path.join(files_dir, images_dir)\n",
    "size=(2048,2048)\n",
    "img,input_name,output_name,datacsv,pixel_size={},{},{},{},{}\n",
    "\n",
    "path = Path(joined_path)\n",
    "files = list(path.glob(\"*.ome.tif\"))\n",
    "files.extend(list(path.glob(\"*.csv\")))\n",
    "\n",
    "\n",
    "for input_file in files:\n",
    "    input_file = str(input_file.name)\n",
    "    joined_file_path = os.path.join(files_dir, images_dir, input_file)\n",
    "    if '.tif' in input_file:\n",
    "        tif  = tifffile.TiffFile(joined_file_path)\n",
    "        mdInfoDict = xmltodict.parse(tif.ome_metadata, force_list={'Plane'})\n",
    "        date, cell_type, dye, bf_fl, index  = input_file.split('_')\n",
    "        number, ome, tiff= index.split('.')\n",
    "        ##\n",
    "        if int(number)==1 or int(number)==2 or int(number)==4 or int(number)==8:\n",
    "            pixel_size_value=0\n",
    "            pixel_size[int(number)-1]=1\n",
    "        else:\n",
    "            pixel_size_value=1\n",
    "            pixel_size[int(number)-1]=0.103\n",
    "        ##\n",
    "        img[int(number)-1] = Image.open(joined_file_path)\n",
    "        input_name[int(number)-1]= f'points_{date}_{cell_type}_{bf_fl}_{number}'\n",
    "        output_name[int(number)-1]= f'image_{date}_{cell_type}_{bf_fl}_{number}'\n",
    "        print('Loaded image:'+input_file)\n",
    "    else:\n",
    "        labels, index, bf_fl  = input_file.split('_')\n",
    "        datacsv[int(index)-1] = pd.read_csv(joined_file_path)\n",
    "        print('Loaded csv:'+ input_file)\n",
    "print('Pixel scaling:',pixel_size)\n",
    "max_number=int(len(datacsv))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all Gaussian Points of Interest ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(max_number):\n",
    "    csv=datacsv[x]\n",
    "    im=img[x]\n",
    "    ##\n",
    "    scale_value=float(pixel_size[x])\n",
    "    print('scaling by',scale_value)\n",
    "    print(csv['axis-1'][1])\n",
    "    csv['axis-1']=csv['axis-1']*(1/scale_value)\n",
    "    print(csv['axis-1'][1])\n",
    "    csv['axis-2']=csv['axis-2']*(1/scale_value)\n",
    "    ##\n",
    "    for i in range(2,7,1):\n",
    "        sigma=(i,i)\n",
    "        s=sigma[0]\n",
    "        in_name=f'{input_name[x]}_sigma{s}.tiff'\n",
    "        framenum=im.n_frames\n",
    "        poi(csv,in_name,sigma,size,framenum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut Images and Gaussian POIs ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir= BASE_DIR\n",
    "training_dir = os.path.join(base_dir, 'training_data')\n",
    "folder_name=images_dir+'_pos'\n",
    "filepath= os.path.join(training_dir , folder_name)\n",
    "tif_files = list(item for item in files if \".tif\" in item.name)\n",
    "\n",
    "folder_dict = get_dict(images_dir)\n",
    "delete_old_extracted_events(folder_dict, os.path.join(training_dir, images_dir))\n",
    "event_dict = copy.deepcopy(folder_dict)\n",
    "event_dict['type'] = \"event\"\n",
    "del event_dict['extracted_events']\n",
    "\n",
    "for x in range(max_number):\n",
    "    event_dict['original_file'] = os.path.basename(tif_files[x])\n",
    "    event_dict['event_content'] = 'division'\n",
    "    \n",
    "    csv=datacsv[x]\n",
    "    im=img[x]\n",
    "    print('file number:',x+1)\n",
    "    ##\n",
    "    # scale_value=float(pixel_size[x])\n",
    "    # print('scaling by',scale_value)\n",
    "    # print(csv['axis-1'][1])\n",
    "    # csv['axis-1']=csv['axis-1']*(1/scale_value)\n",
    "    # print(csv['axis-1'][1])\n",
    "    # csv['axis-2']=csv['axis-2']*(1/scale_value)\n",
    "    ##\n",
    "    list1=event_separation(csv)\n",
    "    l=len(list1)\n",
    "    out_name=f'{output_name[x]}'\n",
    "    image_crop(l,list1, csv, im,0, out_name,filepath, SAVING_SCHEME=SAVING_SCHEME,\n",
    "               folder_dict=folder_dict, event_dict=event_dict)\n",
    "\n",
    "    for i in range(2,7,1):\n",
    "        sigma=(i,i)\n",
    "        s=sigma[0]\n",
    "        print('sigma:',s)\n",
    "        in_name=f'{input_name[x]}_sigma{s}.tiff'\n",
    "        out_name_g=f'{output_name[x]}_sigma{s}'\n",
    "        \n",
    "        gauss=base_dir+f'\\{in_name}'\n",
    "        gauss_image=Image.open(gauss)\n",
    "        image_crop(l,list1, csv, gauss_image,1, out_name_g,filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut Negative Frames ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir= r'C:\\Users\\roumba\\Documents\\Software\\deep-events'\n",
    "training_dir= r'C:\\Users\\roumba\\Documents\\Software\\deep-events\\training_data'\n",
    "folder_name=images_dir+'_neg'\n",
    "filepath= os.path.join(training_dir , folder_name)\n",
    "from myfunctions import image_crop_negative\n",
    "\n",
    "for x in range(max_number):\n",
    "    csv=datacsv[x]\n",
    "    im=img[x]\n",
    "    print('file number:',x)\n",
    "    out_name=f'{output_name[x]}'\n",
    "\n",
    "    list1=event_separation(csv)\n",
    "    l=len(list1)\n",
    "    image_crop_negative(l,list1, csv, im, out_name,filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1eaf8819518d82bc7e7f729f546a337f692f85bf6d00cdfaf0712e2fc6595813"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
