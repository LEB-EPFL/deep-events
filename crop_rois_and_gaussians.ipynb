{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220915_mtstaygold_cos7_ZEISS_bf\n",
      "220915_mtstaygold_cos7_ZEISS_fl\n",
      "220921_mtstaygold_cos7_iSIM_fl\n",
      "220922_mtstaygold_U2OS_iSIM_fl\n",
      "220927_mitotrackergreen_cos7_ZEISS_bf\n",
      "220927_mitotrackergreen_cos7_ZEISS_fl\n",
      "220928_mtstaygold_U2OS_iSIM_fl\n",
      "221123_mtStayGold_cos7_ZEISS_bf\n",
      "221123_mtStayGold_cos7_ZEISS_fl\n",
      "221123_mtStayGold_U2OS_ZEISS_fl\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os import path\n",
    "import xmltodict\n",
    "from myfunctions import event_separation , image_crop, image_crop_negative, poi\n",
    "from myfunctions import delete_old_extracted_events\n",
    "from database.extract_yaml import get_dict\n",
    "import tifffile\n",
    "from pathlib import Path\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = r'//lebnas1.epfl.ch/microsc125/deep_events'\n",
    "SAVING_SCHEME = \"ws_0.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data from a folder ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 5, got 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m tif  \u001b[39m=\u001b[39m tifffile\u001b[39m.\u001b[39mTiffFile(joined_file_path)\n\u001b[0;32m     16\u001b[0m mdInfoDict \u001b[39m=\u001b[39m xmltodict\u001b[39m.\u001b[39mparse(tif\u001b[39m.\u001b[39mome_metadata, force_list\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mPlane\u001b[39m\u001b[39m'\u001b[39m})\n\u001b[1;32m---> 17\u001b[0m date, cell_type, dye, bf_fl, index  \u001b[39m=\u001b[39m input_file\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     18\u001b[0m number, ome, tiff\u001b[39m=\u001b[39m index\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[39m##\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 5, got 4)"
     ]
    }
   ],
   "source": [
    "files_dir = os.path.join(BASE_DIR, 'original_data')\n",
    "images_dir = '220915_mtstaygold_cos7_ZEISS_bf'\n",
    "joined_path = os.path.join(files_dir, images_dir)\n",
    "size=(2048,2048)\n",
    "img,input_name,output_name,datacsv,pixel_size={},{},{},{},{}\n",
    "\n",
    "path = Path(joined_path)\n",
    "files = list(path.glob(\"*.ome.tif\"))\n",
    "files.extend(list(path.glob(\"*.csv\")))\n",
    "\n",
    "for input_file in files:\n",
    "    input_file = str(input_file.name)\n",
    "    joined_file_path = os.path.join(files_dir, images_dir, input_file)\n",
    "    if '.tif' in input_file:\n",
    "        tif  = tifffile.TiffFile(joined_file_path)\n",
    "        mdInfoDict = xmltodict.parse(tif.ome_metadata, force_list={'Plane'})\n",
    "        date, cell_type, dye, bf_fl, index  = input_file.split('_')\n",
    "        number, ome, tiff= index.split('.')\n",
    "        ##\n",
    "        # if int(number)==1 or int(number)==2 or int(number)==4 or int(number)==8:\n",
    "        #     pixel_size_value=0\n",
    "        #     pixel_size[int(number)-1]=1\n",
    "        # else:\n",
    "        #     pixel_size_value=1\n",
    "        #     pixel_size[int(number)-1]=0.103\n",
    "        ##\n",
    "        img[int(number)-1] = Image.open(joined_file_path)\n",
    "        input_name[int(number)-1]= f'points_{date}_{cell_type}_{bf_fl}_{number}'\n",
    "        output_name[int(number)-1]= f'image_{date}_{cell_type}_{bf_fl}_{number}'\n",
    "        print('Loaded image:'+input_file)\n",
    "    else:\n",
    "        labels, index, bf_fl  = input_file.split('_')\n",
    "        datacsv[int(index)-1] = pd.read_csv(joined_file_path)\n",
    "        print('Loaded csv:'+ input_file)\n",
    "print('Pixel scaling:',pixel_size)\n",
    "max_number=int(len(datacsv))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all Gaussian Points of Interest ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaling by 1.0\n",
      "447.8902914058857\n",
      "447.8902914058857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:36<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaling by 1.0\n",
      "604.2610117654115\n",
      "604.2610117654115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 126/126 [00:35<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaling by 0.103\n",
      "1234.9410873670988\n",
      "11989.719294826204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/98 [00:00<?, ?it/s]c:\\Users\\stepp\\Documents\\05_Software\\deep-events\\myfunctions.py:268: RuntimeWarning: invalid value encountered in divide\n",
      "  gaussian_points = gaussian_points/np.max(gaussian_points)                                               #divides by the max\n",
      "100%|██████████| 98/98 [00:27<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaling by 1.0\n",
      "775.1290823966419\n",
      "775.1290823966419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:15<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaling by 0.103\n",
      "499.51039898937927\n",
      "4849.615524168731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:13<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaling by 0.103\n",
      "1795.0167814977149\n",
      "17427.3473931817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:23<00:00,  3.47it/s]\n"
     ]
    }
   ],
   "source": [
    "for x in range(max_number):\n",
    "    csv=datacsv[x]\n",
    "    im=img[x]\n",
    "    ##\n",
    "    scale_value=float(pixel_size[x])\n",
    "    print('scaling by',scale_value)\n",
    "    print(csv['axis-1'][1])\n",
    "    csv['axis-1']=csv['axis-1']*(1/scale_value)\n",
    "    print(csv['axis-1'][1])\n",
    "    csv['axis-2']=csv['axis-2']*(1/scale_value)\n",
    "    ##\n",
    "    for i in range(6,7,1):\n",
    "        sigma=(i,i)\n",
    "        s=sigma[0]\n",
    "        in_name=f'{input_name[x]}_sigma{s}.tiff'\n",
    "        framenum=im.n_frames\n",
    "        poi(csv,in_name,sigma,size,framenum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut Images and Gaussian POIs ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file number: 1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argument of type 'NoneType' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m l\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(list1)\n\u001b[0;32m     22\u001b[0m out_name\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00moutput_name[x]\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m---> 23\u001b[0m event_dict \u001b[39m=\u001b[39m image_crop(l,list1, csv, im,\u001b[39m0\u001b[39;49m, out_name,filepath)\n\u001b[0;32m     25\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m6\u001b[39m,\u001b[39m7\u001b[39m,\u001b[39m1\u001b[39m):\n\u001b[0;32m     26\u001b[0m     sigma\u001b[39m=\u001b[39m(i,i)\n",
      "File \u001b[1;32mc:\\Users\\stepp\\Documents\\05_Software\\deep-events\\myfunctions.py:95\u001b[0m, in \u001b[0;36mimage_crop\u001b[1;34m(l, list_of_divisions, data, img, g_state, outputname, foldname, SAVING_SCHEME, folder_dict, event_dict)\u001b[0m\n\u001b[0;32m     91\u001b[0m     imcrop\u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mcrop(box)\n\u001b[0;32m     93\u001b[0m     dataar[frame_index, :, :] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(imcrop)\n\u001b[1;32m---> 95\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39;49m\u001b[39mws\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39min\u001b[39;49;00m SAVING_SCHEME:\n\u001b[0;32m     96\u001b[0m     \u001b[39m# Adjust the names to the database optimized saving scheme\u001b[39;00m\n\u001b[0;32m     97\u001b[0m     \u001b[39mif\u001b[39;00m g_state \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     98\u001b[0m         path, folder_dict, event_id \u001b[39m=\u001b[39m get_save_info(foldname, folder_dict)\n",
      "\u001b[1;31mTypeError\u001b[0m: argument of type 'NoneType' is not iterable"
     ]
    }
   ],
   "source": [
    "base_dir = BASE_DIR\n",
    "training_dir = os.path.join(base_dir, 'training_data')\n",
    "folder_name = images_dir\n",
    "filepath= os.path.join(training_dir , folder_name)\n",
    "\n",
    "\n",
    "for x in range(max_number):\n",
    "    \n",
    "    csv=datacsv[x]\n",
    "    im=img[x]\n",
    "    print('file number:',x+1)\n",
    "    ##\n",
    "    # scale_value=float(pixel_size[x])\n",
    "    # print('scaling by',scale_value)\n",
    "    # print(csv['axis-1'][1])\n",
    "    # csv['axis-1']=csv['axis-1']*(1/scale_value)\n",
    "    # print(csv['axis-1'][1])\n",
    "    # csv['axis-2']=csv['axis-2']*(1/scale_value)\n",
    "    ##\n",
    "    list1=event_separation(csv)\n",
    "    l=len(list1)\n",
    "    out_name=f'{output_name[x]}'\n",
    "    event_dict = image_crop(l,list1, csv, im,0, out_name,filepath)\n",
    "\n",
    "    for i in range(6,7,1):\n",
    "        sigma=(i,i)\n",
    "        s=sigma[0]\n",
    "        print('sigma:',s)\n",
    "        in_name=f'{input_name[x]}_sigma{s}.tiff'\n",
    "        out_name_g=f'{output_name[x]}_sigma{s}'\n",
    "        \n",
    "        gauss=base_dir+f'\\{in_name}'\n",
    "        gauss_image=Image.open(gauss)\n",
    "        image_crop(l,list1, csv, gauss_image,1, out_name,filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut images and gaussians DATABASE style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file number: 1\n",
      "sigma: 6\n",
      "sigma: 6\n",
      "sigma: 6\n",
      "sigma: 6\n",
      "sigma: 6\n",
      "sigma: 6\n",
      "sigma: 6\n",
      "sigma: 6\n",
      "sigma: 6\n",
      "sigma: 6\n",
      "sigma: 6\n",
      "sigma: 6\n",
      "sigma: 6\n",
      "sigma: 6\n",
      "sigma: 6\n",
      "sigma: 6\n",
      "sigma: 6\n",
      "sigma: 6\n",
      "sigma: 6\n",
      "sigma: 6\n",
      "sigma: 6\n",
      "sigma: 6\n",
      "file number: 2\n",
      "sigma: 6\n",
      "sigma: 6\n",
      "sigma: 6\n",
      "sigma: 6\n",
      "sigma: 6\n",
      "sigma: 6\n",
      "sigma: 6\n",
      "sigma: 6\n",
      "sigma: 6\n",
      "sigma: 6\n",
      "sigma: 6\n",
      "sigma: 6\n",
      "sigma: 6\n"
     ]
    },
    {
     "ename": "EOFError",
     "evalue": "attempt to seek outside sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 36\u001b[0m\n\u001b[0;32m     34\u001b[0m event \u001b[39m=\u001b[39m [event]\n\u001b[0;32m     35\u001b[0m out_name\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00moutput_name[x]\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m---> 36\u001b[0m event_dict \u001b[39m=\u001b[39m image_crop(\u001b[39m1\u001b[39;49m,event, csv, im,\u001b[39m0\u001b[39;49m, out_name,filepath, SAVING_SCHEME\u001b[39m=\u001b[39;49mSAVING_SCHEME,\n\u001b[0;32m     37\u001b[0m         folder_dict\u001b[39m=\u001b[39;49mfolder_dict, event_dict\u001b[39m=\u001b[39;49mevent_dict)\n\u001b[0;32m     39\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m6\u001b[39m,\u001b[39m7\u001b[39m,\u001b[39m1\u001b[39m):\n\u001b[0;32m     40\u001b[0m     sigma\u001b[39m=\u001b[39m(i,i)\n",
      "File \u001b[1;32mc:\\Users\\stepp\\Documents\\05_Software\\deep-events\\myfunctions.py:89\u001b[0m, in \u001b[0;36mimage_crop\u001b[1;34m(l, list_of_divisions, data, img, g_state, outputname, foldname, SAVING_SCHEME, folder_dict, event_dict)\u001b[0m\n\u001b[0;32m     86\u001b[0m dataar\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mzeros((frame2\u001b[39m-\u001b[39mframe1\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m256\u001b[39m, \u001b[39m256\u001b[39m))\n\u001b[0;32m     88\u001b[0m \u001b[39mfor\u001b[39;00m frame_index, frame_number \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mrange\u001b[39m (frame1, frame2\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)):\n\u001b[1;32m---> 89\u001b[0m     img\u001b[39m.\u001b[39;49mseek(frame_number) \u001b[39m#starts from 0 I think?\u001b[39;00m\n\u001b[0;32m     90\u001b[0m     box \u001b[39m=\u001b[39m (xcrop2, ycrop2, xcrop1, ycrop1) \u001b[39m#choose dimensions of box\u001b[39;00m\n\u001b[0;32m     91\u001b[0m     imcrop\u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mcrop(box)\n",
      "File \u001b[1;32mc:\\Users\\stepp\\Documents\\05_Software\\deep-events\\deep_events\\lib\\site-packages\\PIL\\TiffImagePlugin.py:1104\u001b[0m, in \u001b[0;36mTiffImageFile.seek\u001b[1;34m(self, frame)\u001b[0m\n\u001b[0;32m   1102\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mseek\u001b[39m(\u001b[39mself\u001b[39m, frame):\n\u001b[0;32m   1103\u001b[0m     \u001b[39m\"\"\"Select a given frame as current image\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1104\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_seek_check(frame):\n\u001b[0;32m   1105\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m   1106\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_seek(frame)\n",
      "File \u001b[1;32mc:\\Users\\stepp\\Documents\\05_Software\\deep-events\\deep_events\\lib\\site-packages\\PIL\\ImageFile.py:313\u001b[0m, in \u001b[0;36mImageFile._seek_check\u001b[1;34m(self, frame)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_seek_check\u001b[39m(\u001b[39mself\u001b[39m, frame):\n\u001b[0;32m    304\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    305\u001b[0m         frame \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_min_frame\n\u001b[0;32m    306\u001b[0m         \u001b[39m# Only check upper limit on frames if additional seek operations\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    311\u001b[0m         )\n\u001b[0;32m    312\u001b[0m     ):\n\u001b[1;32m--> 313\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mEOFError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mattempt to seek outside sequence\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    315\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtell() \u001b[39m!=\u001b[39m frame\n",
      "\u001b[1;31mEOFError\u001b[0m: attempt to seek outside sequence"
     ]
    }
   ],
   "source": [
    "base_dir = BASE_DIR\n",
    "training_dir = os.path.join(base_dir, 'training_data')\n",
    "if \"ws\" in SAVING_SCHEME:\n",
    "    folder_name = images_dir\n",
    "else:\n",
    "    folder_name=images_dir+'_pos'\n",
    "filepath= os.path.join(training_dir , folder_name)\n",
    "\n",
    "tif_files = list(item for item in files if \".tif\" in item.name)\n",
    "folder_dict = get_dict(images_dir,os.path.join(BASE_DIR, \"original_data\"))\n",
    "delete_old_extracted_events(folder_dict, os.path.join(training_dir, images_dir))\n",
    "event_dict = copy.deepcopy(folder_dict)\n",
    "event_dict['type'] = \"event\"\n",
    "del event_dict['extracted_events']\n",
    "\n",
    "for x in range(max_number):\n",
    "    event_dict['original_file'] = os.path.basename(tif_files[x])\n",
    "    event_dict['event_content'] = 'division'\n",
    "    \n",
    "    csv=datacsv[x]\n",
    "    im=img[x]\n",
    "    print('file number:',x+1)\n",
    "    ##\n",
    "    # scale_value=float(pixel_size[x])\n",
    "    # print('scaling by',scale_value)\n",
    "    # print(csv['axis-1'][1])\n",
    "    # csv['axis-1']=csv['axis-1']*(1/scale_value)\n",
    "    # print(csv['axis-1'][1])\n",
    "    # csv['axis-2']=csv['axis-2']*(1/scale_value)\n",
    "    ##\n",
    "    list1=event_separation(csv)\n",
    "    l=len(list1)\n",
    "    for event in list1:\n",
    "        event = [event]\n",
    "        out_name=f'{output_name[x]}'\n",
    "        event_dict = image_crop(1,event, csv, im,0, out_name,filepath, SAVING_SCHEME=SAVING_SCHEME,\n",
    "                folder_dict=folder_dict, event_dict=event_dict)\n",
    "\n",
    "        for i in range(6,7,1):\n",
    "            sigma=(i,i)\n",
    "            s=sigma[0]\n",
    "            print('sigma:',s)\n",
    "            in_name=f'{input_name[x]}_sigma{s}.tiff'\n",
    "            out_name_g=f'{output_name[x]}_sigma{s}'\n",
    "            \n",
    "            gauss=base_dir+f'\\{in_name}'\n",
    "            gauss_image=Image.open(gauss)\n",
    "            image_crop(1,event, csv, gauss_image,1, out_name,filepath, SAVING_SCHEME=SAVING_SCHEME,\n",
    "                folder_dict=folder_dict, event_dict=event_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut Negative Frames ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir= r'C:\\Users\\roumba\\Documents\\Software\\deep-events'\n",
    "training_dir= r'C:\\Users\\roumba\\Documents\\Software\\deep-events\\training_data'\n",
    "folder_name=images_dir+'_neg'\n",
    "filepath= os.path.join(training_dir , folder_name)\n",
    "from myfunctions import image_crop_negative\n",
    "\n",
    "for x in range(max_number):\n",
    "    csv=datacsv[x]\n",
    "    im=img[x]\n",
    "    print('file number:',x)\n",
    "    out_name=f'{output_name[x]}'\n",
    "\n",
    "    list1=event_separation(csv)\n",
    "    l=len(list1)\n",
    "    image_crop_negative(l,list1, csv, im, out_name,filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut Negative Frames DATABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir= BASE_DIR\n",
    "training_dir= os.path.join(BASE_DIR, \"training_data\")\n",
    "folder_name=images_dir\n",
    "filepath= os.path.join(training_dir , folder_name)\n",
    "from myfunctions import image_crop_negative\n",
    "\n",
    "tif_files = list(item for item in files if \".tif\" in item.name)\n",
    "folder_dict = get_dict(images_dir,os.path.join(BASE_DIR, \"original_data\"))\n",
    "# delete_old_extracted_events(folder_dict, os.path.join(training_dir, images_dir))\n",
    "event_dict = copy.deepcopy(folder_dict)\n",
    "event_dict['type'] = \"event\"\n",
    "\n",
    "for x in range(max_number):\n",
    "    event_dict['original_file'] = os.path.basename(tif_files[x])\n",
    "    event_dict['event_content'] = 'negative'\n",
    "\n",
    "    csv=datacsv[x]\n",
    "    im=img[x]\n",
    "    print('file number:',x)\n",
    "    out_name=f'{output_name[x]}'\n",
    "\n",
    "    list1=event_separation(csv)\n",
    "    l=len(list1)\n",
    "\n",
    "    for event in list1:\n",
    "        event = [event]\n",
    "        out_name=f'{output_name[x]}'\n",
    "        event_dict = image_crop_negative(1, event, csv, im out_name,filepath, SAVING_SCHEME=SAVING_SCHEME,\n",
    "                                         folder_dict=folder_dict, event_dict=event_dict)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 ('deep_events': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "311d75c6587d2d52860d2453b22c030776a90eb3018454de7f5f2a544f32be40"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
