{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util\n",
    "import plotting\n",
    "import evaluation\n",
    "import preprocessing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.color import label2rgb\n",
    "from skimage import filters, measure, segmentation\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "plt.rc('xtick', labelsize=18)\n",
    "plt.rc('ytick', labelsize=18)\n",
    "plt.rc('axes', labelsize=20)\n",
    "plt.rc('legend', fontsize=18)\n",
    "\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define GPU device where the code will run on\n",
    "gpu = tf.config.list_physical_devices('GPU')[0]\n",
    "print(gpu)\n",
    "tf.config.experimental.set_memory_growth(gpu, True)\n",
    "gpu = tf.device('GPU:0/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'D:/Santi/'\n",
    "data_path = base_dir+'Data/' \n",
    "model_path = base_dir+'Models/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inputs\n",
    "input_data = util.load_h5(data_path, 'Mito')\n",
    "print('Inputs'+':', input_data.shape)\n",
    "\n",
    "#Outputs\n",
    "output_data = util.load_h5(data_path, 'Proc')\n",
    "print('Outputs:', output_data.shape)\n",
    "\n",
    "labels = util.load_h5(data_path, 'labels')\n",
    "print('Labels:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = util.get_filename(model_path, 'ref_f8')\n",
    "idx_sort = np.argsort([int(model_name.split('_b')[-1]) for model_name in folder_name])\n",
    "folder_name = [folder_name[i] for i in idx_sort]\n",
    "nb_models = len(folder_name)\n",
    "\n",
    "model = util.load_model(model_path, ['model']*nb_models, folder_name, as_type=dict)\n",
    "history = util.load_pkl(model_path, ['history']*nb_models, folder_name, as_type=dict)\n",
    "frames_test = util.load_pkl(model_path, ['frames_test']*nb_models, folder_name, as_type=dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_test, output_test, pred_output_test = {}, {}, {}\n",
    "labels_test = {}\n",
    "\n",
    "model_pbar = tqdm(model.keys())\n",
    "for model_name in model_pbar:\n",
    "  model_pbar.set_description(\"Processing %s\" %model_name)\n",
    "  input_test[model_name] = input_data[frames_test[model_name]]\n",
    "  output_test[model_name] = output_data[frames_test[model_name]]\n",
    "  labels_test[model_name] = labels[frames_test[model_name]]\n",
    "\n",
    "  pred_output_test[model_name] = evaluation.predict(input_test[model_name], model[model_name])\n",
    "\n",
    "del output_data, labels, input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_threshold = np.array([0.1, 0.2, 0.3, 0.5])\n",
    "f1_score = {}\n",
    "optimal_pred_threshold = {}\n",
    "pred_labels_test = {}\n",
    "\n",
    "for model_name in model:\n",
    "  print(\"Processing %s\" %model_name)\n",
    "  f1_score[model_name] = evaluation.get_f1_curve(labels_test[model_name], pred_output_test[model_name], pred_threshold)\n",
    "  \n",
    "  optimal_pred_threshold[model_name] = evaluation.get_optimal_threshold(pred_threshold, f1_score[model_name])\n",
    "  \n",
    "  pred_labels_test[model_name] = evaluation.label(pred_output_test[model_name], threshold=optimal_pred_threshold[model_name])\n",
    "  print('\\n')\n",
    "  \n",
    "util.save_pkl(pred_threshold, model_path, 'ref_pred_threshold')\n",
    "util.save_pkl(f1_score, model_path, 'ref_f1_score')\n",
    "util.save_pkl(optimal_pred_threshold, model_path, 'ref_optimal_pred_threshold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = [int(model_name.split('_b')[-1]) for model_name in folder_name]\n",
    "\n",
    "num_models = len(batch_size)\n",
    "cbar_ticks = np.arange(num_models)\n",
    "\n",
    "norm_bounds = -1, num_models-1\n",
    "norm = Normalize(*norm_bounds)\n",
    "cmap = plt.cm.ScalarMappable(cmap='Oranges', norm=norm)\n",
    "colors = cmap.get_cmap()(norm(cbar_ticks))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "for model_name, b, c in zip(model, batch_size, colors):\n",
    "  ax.plot(pred_threshold, f1_score[model_name], 'o-', color=c, label=b)\n",
    "\n",
    "ax.set(xlabel='Normalized event score threshold', ylabel='F1-score', ylim=(0, 1))\n",
    "ax.legend(title='Batch size', title_fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'ref_examples'\n",
    "filename = base_dir+'Figures/'+title+'.pdf'\n",
    "print(filename)\n",
    "\n",
    "title_size = 36\n",
    "\n",
    "fig, axes = plt.subplots(2, nb_models, figsize=(4*nb_models, 8))\n",
    "fig.suptitle('Batch size', size=title_size)\n",
    "for model_name, b, i in zip(folder_name, [8, 16, 32, 256], range(nb_models)):\n",
    "  frame = np.random.choice(np.where(np.any(np.any(output_test[model_name]>0, axis=-1), axis=-1))[0])\n",
    "  mask = pred_output_test[model_name][frame]>optimal_pred_threshold[model_name]\n",
    "  plotting.plot_merge(input_test[model_name][frame], output_test[model_name][frame], title='', ax=axes[0, i])\n",
    "  plotting.plot_merge(input_test[model_name][frame], pred_output_test[model_name][frame]*mask, title='', ax=axes[1, i])\n",
    "  axes[0, i].set_title(b, size=title_size)\n",
    "  \n",
    "fig.tight_layout(pad=0)\n",
    "fig.subplots_adjust(wspace=0, hspace=0.02, top=0.85)\n",
    "#plt.show()\n",
    "fig.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in folder_name:\n",
    "  mask = pred_output_test[model_name]>optimal_pred_threshold[model_name]\n",
    "  plotting.plot_outputs(input_test[model_name], output_test[model_name], \n",
    "                        pred_output_test[model_name]*mask, frames_test[model_name], \n",
    "                        nb_examples=5, title=model_name, cmap=['gray', 'inferno'])\n",
    "  plt.show()\n",
    "  print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1eaf8819518d82bc7e7f729f546a337f692f85bf6d00cdfaf0712e2fc6595813"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
